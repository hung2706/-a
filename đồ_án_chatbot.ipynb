{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hung2706/-a/blob/main/%C4%91%E1%BB%93_%C3%A1n_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "n7l24mpnOOYa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "eb03ba2b-e98c-4f87-c37a-e0b8bfdf024f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bc00ce23-64c2-47a1-b8b9-21b033085ff7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bc00ce23-64c2-47a1-b8b9-21b033085ff7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2.xlsx to 2.xlsx\n"
          ]
        }
      ],
      "source": [
        "#TIỀN XỬ LÍ DỮ LIỆU\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "df = pd.read_excel(\"2.xlsx\")\n",
        "df.columns = ['input', 'response']  # Đổi tên cột để dễ dùng về sau\n",
        "df.head()\n",
        "\n",
        "import re\n",
        "# Hàm làm sạch 1 câu\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # chuyển về chữ thường\n",
        "    text = re.sub(r\"[^\\w\\sàáạảãâầấậẩẫăằắặẳẵèéẹẻẽêềếệểễìíịỉĩòóọỏõôồốộổỗơờớợởỡùúụủũưừứựửữỳýỵỷỹđ]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)  # loại bỏ khoảng trắng thừa\n",
        "    return text.strip()\n",
        "# Áp dụng cho cả input và response\n",
        "df['input'] = df['input'].apply(clean_text)\n",
        "df['response'] = df['response'].apply(clean_text)\n",
        "# Thêm token <start> và <end> cho câu trả lời\n",
        "df['response'] = df['response'].apply(lambda x: '<start> ' + x + ' <end>')\n",
        "\n",
        "# Kiểm tra thử vài dòng\n",
        "for i in range(3):\n",
        "    print(f\"Q: {df['input'][i]}\")\n",
        "    print(f\"A: {df['response'][i]}\")\n",
        "    print(\"---\")\n",
        "\n"
      ],
      "metadata": {
        "id": "gFtm3yK9O6Bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "55e9e20d-9856-484f-cf33-197bc5a0edd5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '2.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-10-3242454777.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'response'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Đổi tên cột để dễ dùng về sau\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TOKENIZE\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# 1. Tạo tokenizer CHUNG cho cả input và response\n",
        "shared_tokenizer = Tokenizer(filters='', oov_token='<OOV>')\n",
        "\n",
        "# 2. Huấn luyện tokenizer trên toàn bộ dữ liệu (cả input và response)\n",
        "all_texts = df['input'].tolist() + df['response'].str.replace('<start>|<end>', '').tolist()\n",
        "shared_tokenizer.fit_on_texts(all_texts)\n",
        "\n",
        "# 3. Mã hóa câu\n",
        "encoder_input_sequences = shared_tokenizer.texts_to_sequences(df['input'])\n",
        "\n",
        "# Xử lý response: bỏ <start>/<end> cũ, thêm lại bằng tay để đảm bảo nhất quán\n",
        "temp_sequences = shared_tokenizer.texts_to_sequences(df['response'].str.replace('<start>|<end>', ''))\n",
        "decoder_input_sequences = [\n",
        "    [shared_tokenizer.word_index['<start>']] + seq + [shared_tokenizer.word_index['<end>']]\n",
        "    for seq in temp_sequences\n",
        "]\n",
        "\n",
        "# 4. In thử để kiểm tra\n",
        "for i in range(3):\n",
        "    print(f\"Q{i+1} (chuỗi số):\", encoder_input_sequences[i])\n",
        "    print(f\"A{i+1} (chuỗi số):\", decoder_input_sequences[i])\n",
        "    print(\"---\")\n",
        "\n",
        "# 5. Xem từ điển từ → số (nếu bạn muốn)\n",
        "print(\"Từ điển shared_tokenizer (input + response):\", shared_tokenizer.word_index)\n",
        "\n",
        "# Tính MAX_DECODER_LEN dựa trên độ dài thực tế của câu trả lời\n",
        "MAX_DECODER_LEN = max(len(seq) for seq in decoder_input_sequences)  # Giữ nguyên độ dài tự nhiên\n",
        "print(\"Độ dài tối đa thực tế:\", MAX_DECODER_LEN)  # Kiểm tra xem giá trị hợp lý không (nên < 20)"
      ],
      "metadata": {
        "id": "6aerV3_UQP5w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc4ed1db-04e7-461a-e0ab-7da1a0e81a80"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1 (chuỗi số): [67, 15]\n",
            "A1 (chuỗi số): [2, 2, 15, 4, 4, 150, 42, 10, 3, 3]\n",
            "---\n",
            "Q2 (chuỗi số): [15, 31, 44]\n",
            "A2 (chuỗi số): [2, 2, 15, 31, 44, 101, 4, 26, 24, 151, 152, 3, 3]\n",
            "---\n",
            "Q3 (chuỗi số): [15, 31, 32]\n",
            "A3 (chuỗi số): [2, 2, 15, 31, 32, 4, 153, 100, 32, 28, 3, 3]\n",
            "---\n",
            "Từ điển shared_tokenizer (input + response): {'<OOV>': 1, '<start>': 2, '<end>': 3, 'bạn': 4, 'là': 5, 'có': 6, 'không': 7, 'mình': 8, 'bằng': 9, 'gì': 10, '2': 11, 'học': 12, 'bao': 13, 'nhiêu': 14, 'chào': 15, 'nhé': 16, 'đâu': 17, 'hôm': 18, 'nay': 19, 'trời': 20, 'biết': 21, 'thể': 22, 'mấy': 23, 'ngày': 24, '5': 25, 'một': 26, 'từ': 27, 'chưa': 28, 'được': 29, 'nè': 30, 'buổi': 31, 'tối': 32, 'đang': 33, 'cộng': 34, '3': 35, 'nhân': 36, '4': 37, 'python': 38, 'trong': 39, 'máy': 40, 'đi': 41, 'giúp': 42, 'của': 43, 'sáng': 44, 'nhiều': 45, 'giờ': 46, 'độ': 47, 'đẹp': 48, 'trừ': 49, '6': 50, 'chia': 51, 'trình': 52, 'đầu': 53, 'tính': 54, 'giải': 55, 'x': 56, 'hát': 57, 'chuyện': 58, 'sống': 59, 'rất': 60, 'để': 61, 'đó': 62, 'vào': 63, 'luôn': 64, 'nhưng': 65, 'và': 66, 'xin': 67, 'gặp': 68, 'lại': 69, 'sau': 70, 'cảm': 71, 'ơn': 72, 'khỏe': 73, 'làm': 74, 'ở': 75, 'mai': 76, 'mưa': 77, 'nắng': 78, 'lạnh': 79, 'gió': 80, 'bão': 81, '10': 82, 'bậc': 83, 'hai': 84, '9': 85, '1': 86, 'lập': 87, 'khó': 88, 'cách': 89, 'ra': 90, 'tạo': 91, 'bắt': 92, 'hàm': 93, 'dạng': 94, 'tích': 95, 'kể': 96, 'thích': 97, 'chơi': 98, 'nấu': 99, 'ăn': 100, 'chúc': 101, 'tuyệt': 102, 'vời': 103, 'vui': 104, 'phục': 105, 'vụ': 106, 'lệnh': 107, 'trên': 108, 'tập': 109, 'nhẹ': 110, 'c': 111, 'sẽ': 112, 'như': 113, 'print': 114, 'ví': 115, 'dụ': 116, 'lời': 117, 'bài': 118, 'lắm': 119, 'hỏi': 120, 'còn': 121, 'rồi': 122, 'nơi': 123, 'tạm': 124, 'biệt': 125, 'bây': 126, 'thứ': 127, 'nhiệt': 128, 'căn': 129, '100': 130, '20': 131, '8': 132, '7': 133, 'in': 134, 'màn': 135, 'hình': 136, 'biến': 137, 'trí': 138, 'tuệ': 139, 'đạo': 140, 'số': 141, 'phương': 142, 'buồn': 143, 'cười': 144, 'người': 145, 'yêu': 146, 'ma': 147, 'game': 148, 'tuổi': 149, 'cần': 150, 'tốt': 151, 'lành': 152, 'đã': 153, 'hẹn': 154, 'okay': 155, 'hân': 156, 'hạnh': 157, 'lúc': 158, 'nào': 159, 'cũng': 160, 'chờ': 161, 'xem': 162, 'điện': 163, 'thoại': 164, 'nha': 165, 'kiểm': 166, 'tra': 167, 'lịch': 168, 'chiều': 169, 'khoảng': 170, '30': 171, 'se': 172, 'sớm': 173, 'mát': 174, 'mẻ': 175, 'hiện': 176, 'tại': 177, 'tâm': 178, 'trạng': 179, 'vậy': 180, '24': 181, '80': 182, '13': 183, '45': 184, 'ơi': 185, 'mới': 186, 'hơi': 187, 'kiên': 188, 'trì': 189, 'quen': 190, 'thôi': 191, 'ngôn': 192, 'ngữ': 193, 'dễ': 194, 'mạnh': 195, 'mẽ': 196, 'dùng': 197, 'lưu': 198, 'trữ': 199, 'giá': 200, 'trị': 201, 'các': 202, 'khái': 203, 'niệm': 204, 'cơ': 205, 'bản': 206, 'thuật': 207, 'toán': 208, 'tìm': 209, 'tốc': 210, 'thay': 211, 'đổi': 212, 'môn': 213, 'ax²': 214, 'bx': 215, '0': 216, 'cùng': 217, 'lĩnh': 218, 'vực': 219, 'tự': 220, 'dữ': 221, 'liệu': 222, 'vì': 223, 'nói': 224, 'với': 225, 'con': 226, 'vịt': 227, 'qua': 228, 'đường': 229, 'bị': 230, 'thế': 231, 'cày': 232, 'code': 233, 'đỡ': 234, 'chứ': 235, 'giỏi': 236, 'trò': 237, 'trả': 238, 'nhanh': 239, 'năm': 240, 'thì': 241, 'sao': 242, 'công': 243, 'thức': 244, 'ngon': 245, '2024': 246, 'thấy': 247, 'sinh': 248, '2025': 249}\n",
            "Độ dài tối đa thực tế: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  #PADDING\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_ENCODER_LEN = 15  # Độ dài tối đa cho câu hỏi\n",
        "MAX_DECODER_LEN = 20  # Độ dài tối đa cho câu trả lời\n",
        "# Dịch chuyển decoder_input_sequences sang trái 1 bước để tạo decoder_target_sequences\n",
        "decoder_target_sequences = [seq[1:] for seq in decoder_input_sequences]\n",
        "\n",
        "# Để đồng bộ độ dài, bạn có thể thêm 0 ở cuối mỗi câu (vì đã bỏ 1 phần tử đầu)\n",
        "decoder_target_sequences = [seq + [0] for seq in decoder_target_sequences]\n",
        "\n",
        "# Padding cho encoder input (câu hỏi)\n",
        "encoder_input_padded = pad_sequences(encoder_input_sequences, maxlen=MAX_ENCODER_LEN, padding='post', truncating='post')\n",
        "\n",
        "# Padding cho decoder input (câu trả lời đầu vào)\n",
        "decoder_input_padded = pad_sequences(decoder_input_sequences, maxlen=MAX_DECODER_LEN, padding='post', truncating='post')\n",
        "\n",
        "# Padding cho decoder output (dịch chuyển một bước để so sánh khi huấn luyện)\n",
        "decoder_target_padded = pad_sequences(decoder_target_sequences, maxlen=MAX_DECODER_LEN, padding='post', truncating='post')\n",
        "\n",
        "import numpy as np\n",
        "decoder_target_padded = np.expand_dims(decoder_target_padded, -1)\n",
        "\n",
        "print(\"encoder_input_padded.shape:\", encoder_input_padded.shape)\n",
        "print(\"decoder_input_padded.shape:\", decoder_input_padded.shape)\n",
        "print(\"decoder_target_padded.shape:\", decoder_target_padded.shape)\n"
      ],
      "metadata": {
        "id": "zsxfPaDZRHTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf6eb12-96a0-42c9-ce65-3103778aefc8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_input_padded.shape: (400, 15)\n",
            "decoder_input_padded.shape: (400, 20)\n",
            "decoder_target_padded.shape: (400, 20, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TIẾP TỤC Ở ĐÂY :::\n"
      ],
      "metadata": {
        "id": "MwGb6ga7577N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "#EN+DECODER\n",
        "DROPOUT_RATE = 0.2\n",
        "EMBEDDING_DIM = 64  # Giảm do dataset nhỏ\n",
        "LATENT_DIM = 128\n",
        "\n",
        "from tensorflow.keras.layers import Dot, Activation\n",
        "from tensorflow.keras.layers import AdditiveAttention, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "\n",
        "# Số lượng từ trong tokenizer\n",
        "VOCAB_SIZE = len(shared_tokenizer.word_index) + 1\n",
        "# Siêu tham số\n",
        "EMBEDDING_DIM = 128\n",
        "LATENT_DIM = 256\n",
        "\n",
        "# ENCODER\n",
        "encoder_inputs = Input(shape=(MAX_ENCODER_LEN,))\n",
        "encoder_embedding = Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM)(encoder_inputs)\n",
        "encoder_lstm_outputs, state_h, state_c = LSTM(\n",
        "    LATENT_DIM,\n",
        "    return_sequences=True,\n",
        "    return_state=True,\n",
        "    dropout=DROPOUT_RATE  # <== THÊM DROPOUT\n",
        ")(encoder_embedding)\n",
        "\n",
        "# DECODER (phần training)\n",
        "decoder_inputs = Input(shape=(MAX_DECODER_LEN,))\n",
        "decoder_embedding = Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM)(decoder_inputs)\n",
        "decoder_lstm_outputs, _, _ = LSTM(\n",
        "    LATENT_DIM,\n",
        "    return_sequences=True,\n",
        "    return_state=True,\n",
        "    dropout=DROPOUT_RATE  # <== THÊM DROPOUT\n",
        ")(decoder_embedding, initial_state=[state_h, state_c])\n",
        "\n",
        "# ATTENTION\n",
        "attention_layer = AdditiveAttention()([decoder_lstm_outputs, encoder_lstm_outputs])\n",
        "context = attention_layer\n",
        "decoder_combined_context = Concatenate(axis=-1)([context, decoder_lstm_outputs])\n",
        "\n",
        "# COMBINE CONTEXT + DECODER\n",
        "decoder_combined_context = Concatenate(axis=-1)([context, decoder_lstm_outputs])\n",
        "decoder_outputs = Dense(VOCAB_SIZE, activation='softmax')(decoder_combined_context)\n",
        "\n",
        "class TeacherForcingScheduler(Callback):\n",
        "    def __init__(self, initial_prob=1.0):\n",
        "        self.prob = initial_prob\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        # Giảm dần teacher forcing từ 100% -> 50% sau 10 epochs\n",
        "        self.prob = max(0.5, 1.0 - epoch/10)\n",
        "        print(f\"\\nEpoch {epoch+1}: Teacher Forcing Prob = {self.prob:.2f}\")\n",
        "\n",
        "\n",
        "# MODEL\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "GxeiaFVh57ZT",
        "outputId": "c0e6e26f-da82-4599-eb82-7e6843a25cb1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m32,000\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m32,000\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m394,240\u001b[0m │ embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m394,240\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ additive_attention… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ additive_attenti… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m250\u001b[0m)   │    \u001b[38;5;34m128,250\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,000</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,000</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ additive_attention… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ additive_attenti… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">128,250</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m980,986\u001b[0m (3.74 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">980,986</span> (3.74 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m980,986\u001b[0m (3.74 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">980,986</span> (3.74 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [TeacherForcingScheduler()]\n",
        "model.fit([encoder_input_padded, decoder_input_padded], decoder_target_padded,\n",
        "          batch_size=32,\n",
        "          epochs=50,\n",
        "          validation_split=0.1,\n",
        "          callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwBaAn628p9w",
        "outputId": "a0d1d220-265c-4fd1-b14f-f5604dc74333"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: Teacher Forcing Prob = 1.00\n",
            "Epoch 1/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 249ms/step - accuracy: 0.3562 - loss: 4.8893 - val_accuracy: 0.5288 - val_loss: 2.6748\n",
            "\n",
            "Epoch 2: Teacher Forcing Prob = 0.90\n",
            "Epoch 2/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 189ms/step - accuracy: 0.5500 - loss: 2.4823 - val_accuracy: 0.5500 - val_loss: 2.3078\n",
            "\n",
            "Epoch 3: Teacher Forcing Prob = 0.80\n",
            "Epoch 3/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - accuracy: 0.5745 - loss: 2.1997 - val_accuracy: 0.5800 - val_loss: 2.1280\n",
            "\n",
            "Epoch 4: Teacher Forcing Prob = 0.70\n",
            "Epoch 4/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 283ms/step - accuracy: 0.5978 - loss: 2.0474 - val_accuracy: 0.6075 - val_loss: 1.9988\n",
            "\n",
            "Epoch 5: Teacher Forcing Prob = 0.60\n",
            "Epoch 5/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 188ms/step - accuracy: 0.6158 - loss: 1.9315 - val_accuracy: 0.6138 - val_loss: 1.9009\n",
            "\n",
            "Epoch 6: Teacher Forcing Prob = 0.50\n",
            "Epoch 6/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - accuracy: 0.6182 - loss: 1.8788 - val_accuracy: 0.6237 - val_loss: 1.8001\n",
            "\n",
            "Epoch 7: Teacher Forcing Prob = 0.50\n",
            "Epoch 7/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - accuracy: 0.6410 - loss: 1.7080 - val_accuracy: 0.6313 - val_loss: 1.7132\n",
            "\n",
            "Epoch 8: Teacher Forcing Prob = 0.50\n",
            "Epoch 8/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 235ms/step - accuracy: 0.6519 - loss: 1.6093 - val_accuracy: 0.6388 - val_loss: 1.6132\n",
            "\n",
            "Epoch 9: Teacher Forcing Prob = 0.50\n",
            "Epoch 9/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - accuracy: 0.6557 - loss: 1.5133 - val_accuracy: 0.6413 - val_loss: 1.5048\n",
            "\n",
            "Epoch 10: Teacher Forcing Prob = 0.50\n",
            "Epoch 10/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 184ms/step - accuracy: 0.6463 - loss: 1.4714 - val_accuracy: 0.6475 - val_loss: 1.4042\n",
            "\n",
            "Epoch 11: Teacher Forcing Prob = 0.50\n",
            "Epoch 11/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - accuracy: 0.6553 - loss: 1.3639 - val_accuracy: 0.6687 - val_loss: 1.3077\n",
            "\n",
            "Epoch 12: Teacher Forcing Prob = 0.50\n",
            "Epoch 12/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 252ms/step - accuracy: 0.6785 - loss: 1.2516 - val_accuracy: 0.6913 - val_loss: 1.2171\n",
            "\n",
            "Epoch 13: Teacher Forcing Prob = 0.50\n",
            "Epoch 13/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 186ms/step - accuracy: 0.7021 - loss: 1.1711 - val_accuracy: 0.6975 - val_loss: 1.1343\n",
            "\n",
            "Epoch 14: Teacher Forcing Prob = 0.50\n",
            "Epoch 14/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 0.7199 - loss: 1.0785 - val_accuracy: 0.7013 - val_loss: 1.0798\n",
            "\n",
            "Epoch 15: Teacher Forcing Prob = 0.50\n",
            "Epoch 15/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 206ms/step - accuracy: 0.7298 - loss: 0.9996 - val_accuracy: 0.7475 - val_loss: 1.0024\n",
            "\n",
            "Epoch 16: Teacher Forcing Prob = 0.50\n",
            "Epoch 16/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 252ms/step - accuracy: 0.7561 - loss: 0.9407 - val_accuracy: 0.7763 - val_loss: 0.9289\n",
            "\n",
            "Epoch 17: Teacher Forcing Prob = 0.50\n",
            "Epoch 17/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 213ms/step - accuracy: 0.7851 - loss: 0.8794 - val_accuracy: 0.8000 - val_loss: 0.8546\n",
            "\n",
            "Epoch 18: Teacher Forcing Prob = 0.50\n",
            "Epoch 18/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - accuracy: 0.7998 - loss: 0.8130 - val_accuracy: 0.8262 - val_loss: 0.7971\n",
            "\n",
            "Epoch 19: Teacher Forcing Prob = 0.50\n",
            "Epoch 19/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - accuracy: 0.8312 - loss: 0.7342 - val_accuracy: 0.8375 - val_loss: 0.7513\n",
            "\n",
            "Epoch 20: Teacher Forcing Prob = 0.50\n",
            "Epoch 20/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - accuracy: 0.8503 - loss: 0.6722 - val_accuracy: 0.8663 - val_loss: 0.6885\n",
            "\n",
            "Epoch 21: Teacher Forcing Prob = 0.50\n",
            "Epoch 21/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 246ms/step - accuracy: 0.8770 - loss: 0.6069 - val_accuracy: 0.8875 - val_loss: 0.6311\n",
            "\n",
            "Epoch 22: Teacher Forcing Prob = 0.50\n",
            "Epoch 22/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 226ms/step - accuracy: 0.8939 - loss: 0.5504 - val_accuracy: 0.8925 - val_loss: 0.5828\n",
            "\n",
            "Epoch 23: Teacher Forcing Prob = 0.50\n",
            "Epoch 23/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.9058 - loss: 0.5027 - val_accuracy: 0.9100 - val_loss: 0.5288\n",
            "\n",
            "Epoch 24: Teacher Forcing Prob = 0.50\n",
            "Epoch 24/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 181ms/step - accuracy: 0.9186 - loss: 0.4502 - val_accuracy: 0.9137 - val_loss: 0.4832\n",
            "\n",
            "Epoch 25: Teacher Forcing Prob = 0.50\n",
            "Epoch 25/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 262ms/step - accuracy: 0.9298 - loss: 0.3898 - val_accuracy: 0.9288 - val_loss: 0.4458\n",
            "\n",
            "Epoch 26: Teacher Forcing Prob = 0.50\n",
            "Epoch 26/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 198ms/step - accuracy: 0.9403 - loss: 0.3474 - val_accuracy: 0.9338 - val_loss: 0.4099\n",
            "\n",
            "Epoch 27: Teacher Forcing Prob = 0.50\n",
            "Epoch 27/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - accuracy: 0.9478 - loss: 0.3121 - val_accuracy: 0.9425 - val_loss: 0.3676\n",
            "\n",
            "Epoch 28: Teacher Forcing Prob = 0.50\n",
            "Epoch 28/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 200ms/step - accuracy: 0.9589 - loss: 0.2750 - val_accuracy: 0.9512 - val_loss: 0.3426\n",
            "\n",
            "Epoch 29: Teacher Forcing Prob = 0.50\n",
            "Epoch 29/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - accuracy: 0.9637 - loss: 0.2408 - val_accuracy: 0.9512 - val_loss: 0.3226\n",
            "\n",
            "Epoch 30: Teacher Forcing Prob = 0.50\n",
            "Epoch 30/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - accuracy: 0.9681 - loss: 0.2202 - val_accuracy: 0.9600 - val_loss: 0.2942\n",
            "\n",
            "Epoch 31: Teacher Forcing Prob = 0.50\n",
            "Epoch 31/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - accuracy: 0.9754 - loss: 0.1946 - val_accuracy: 0.9575 - val_loss: 0.2749\n",
            "\n",
            "Epoch 32: Teacher Forcing Prob = 0.50\n",
            "Epoch 32/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - accuracy: 0.9754 - loss: 0.1753 - val_accuracy: 0.9600 - val_loss: 0.2550\n",
            "\n",
            "Epoch 33: Teacher Forcing Prob = 0.50\n",
            "Epoch 33/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 232ms/step - accuracy: 0.9813 - loss: 0.1549 - val_accuracy: 0.9663 - val_loss: 0.2397\n",
            "\n",
            "Epoch 34: Teacher Forcing Prob = 0.50\n",
            "Epoch 34/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.9843 - loss: 0.1413 - val_accuracy: 0.9688 - val_loss: 0.2281\n",
            "\n",
            "Epoch 35: Teacher Forcing Prob = 0.50\n",
            "Epoch 35/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - accuracy: 0.9875 - loss: 0.1266 - val_accuracy: 0.9700 - val_loss: 0.2080\n",
            "\n",
            "Epoch 36: Teacher Forcing Prob = 0.50\n",
            "Epoch 36/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - accuracy: 0.9892 - loss: 0.1138 - val_accuracy: 0.9737 - val_loss: 0.2037\n",
            "\n",
            "Epoch 37: Teacher Forcing Prob = 0.50\n",
            "Epoch 37/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 221ms/step - accuracy: 0.9922 - loss: 0.1018 - val_accuracy: 0.9737 - val_loss: 0.1906\n",
            "\n",
            "Epoch 38: Teacher Forcing Prob = 0.50\n",
            "Epoch 38/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - accuracy: 0.9924 - loss: 0.0912 - val_accuracy: 0.9750 - val_loss: 0.1810\n",
            "\n",
            "Epoch 39: Teacher Forcing Prob = 0.50\n",
            "Epoch 39/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 200ms/step - accuracy: 0.9918 - loss: 0.0828 - val_accuracy: 0.9762 - val_loss: 0.1743\n",
            "\n",
            "Epoch 40: Teacher Forcing Prob = 0.50\n",
            "Epoch 40/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 261ms/step - accuracy: 0.9946 - loss: 0.0785 - val_accuracy: 0.9775 - val_loss: 0.1655\n",
            "\n",
            "Epoch 41: Teacher Forcing Prob = 0.50\n",
            "Epoch 41/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 197ms/step - accuracy: 0.9950 - loss: 0.0682 - val_accuracy: 0.9775 - val_loss: 0.1584\n",
            "\n",
            "Epoch 42: Teacher Forcing Prob = 0.50\n",
            "Epoch 42/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - accuracy: 0.9951 - loss: 0.0653 - val_accuracy: 0.9750 - val_loss: 0.1566\n",
            "\n",
            "Epoch 43: Teacher Forcing Prob = 0.50\n",
            "Epoch 43/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - accuracy: 0.9970 - loss: 0.0591 - val_accuracy: 0.9788 - val_loss: 0.1451\n",
            "\n",
            "Epoch 44: Teacher Forcing Prob = 0.50\n",
            "Epoch 44/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - accuracy: 0.9973 - loss: 0.0538 - val_accuracy: 0.9775 - val_loss: 0.1465\n",
            "\n",
            "Epoch 45: Teacher Forcing Prob = 0.50\n",
            "Epoch 45/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - accuracy: 0.9969 - loss: 0.0480 - val_accuracy: 0.9788 - val_loss: 0.1361\n",
            "\n",
            "Epoch 46: Teacher Forcing Prob = 0.50\n",
            "Epoch 46/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 199ms/step - accuracy: 0.9983 - loss: 0.0451 - val_accuracy: 0.9788 - val_loss: 0.1356\n",
            "\n",
            "Epoch 47: Teacher Forcing Prob = 0.50\n",
            "Epoch 47/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - accuracy: 0.9983 - loss: 0.0416 - val_accuracy: 0.9812 - val_loss: 0.1278\n",
            "\n",
            "Epoch 48: Teacher Forcing Prob = 0.50\n",
            "Epoch 48/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.9988 - loss: 0.0390 - val_accuracy: 0.9800 - val_loss: 0.1294\n",
            "\n",
            "Epoch 49: Teacher Forcing Prob = 0.50\n",
            "Epoch 49/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 203ms/step - accuracy: 0.9988 - loss: 0.0356 - val_accuracy: 0.9788 - val_loss: 0.1286\n",
            "\n",
            "Epoch 50: Teacher Forcing Prob = 0.50\n",
            "Epoch 50/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - accuracy: 0.9994 - loss: 0.0319 - val_accuracy: 0.9788 - val_loss: 0.1234\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7868d1d6ae90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. TEST\n",
        "callbacks = [TeacherForcingScheduler()]\n",
        "model.fit([encoder_input_padded, decoder_input_padded], decoder_target_padded,\n",
        "          batch_size=32,\n",
        "          epochs=50,\n",
        "          validation_split=0.1,\n",
        "          callbacks=callbacks)\n",
        "history = model.fit(\n",
        "    [encoder_input_padded, decoder_input_padded],\n",
        "    decoder_target_padded,\n",
        "    batch_size=32,\n",
        "    epochs=50,\n",
        "    validation_split=0.1,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# 2. Xem các metrics đã lưu\n",
        "print(\"Các metrics available:\", history.history.keys())\n",
        "# Output thường có: ['loss', 'accuracy', 'val_loss', 'val_accuracy']\n",
        "\n",
        "# 3. Truy cập các chỉ số cụ thể\n",
        "print(\"Training accuracy cuối cùng:\", history.history['accuracy'][-1])\n",
        "print(\"Validation loss cuối cùng:\", history.history['val_loss'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "RN9f9jwbcACO",
        "outputId": "353a2713-5800-4d44-97d3-4542f91158a4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'TeacherForcingScheduler' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-9-1376493897.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1. TEST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTeacherForcingScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m model.fit([encoder_input_padded, decoder_input_padded], decoder_target_padded,\n\u001b[1;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TeacherForcingScheduler' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 1. Encoder model (giữ nguyên - đã đúng)\n",
        "encoder_model = Model(encoder_inputs, [encoder_lstm_outputs, state_h, state_c])\n",
        "\n",
        "# 2. DECODER MODEL mới - với đầy đủ attention\n",
        "# Inputs cho inference\n",
        "decoder_inputs_single = Input(shape=(1,))  # Mỗi lần chỉ sinh 1 token\n",
        "decoder_state_input_h = Input(shape=(LATENT_DIM,))\n",
        "decoder_state_input_c = Input(shape=(LATENT_DIM,))\n",
        "decoder_hidden_state_input = Input(shape=(MAX_ENCODER_LEN, LATENT_DIM))  # encoder outputs\n",
        "\n",
        "# Embedding layer (dùng lại từ training)\n",
        "decoder_embedding_inf = Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM)(decoder_inputs_single)\n",
        "\n",
        "# LSTM layer (dùng lại từ training)\n",
        "decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
        "decoder_lstm_outputs_inf, state_h_inf, state_c_inf = decoder_lstm(\n",
        "    decoder_embedding_inf,\n",
        "    initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
        ")\n",
        "\n",
        "# ATTENTION MECHANISM\n",
        "attention_layer_inf = AdditiveAttention()(\n",
        "    [decoder_lstm_outputs_inf, decoder_hidden_state_input, decoder_hidden_state_input]\n",
        ")\n",
        "context_inf = attention_layer_inf  # Shape sẽ là (None, 1, 256)\n",
        "decoder_combined_context_inf = Concatenate(axis=-1)([context_inf, decoder_lstm_outputs_inf])\n",
        "\n",
        "# COMBINE CONTEXT + DECODER (giống hệt training!)\n",
        "context_inf = attention_layer_inf  # Bỏ phép nhân với decoder_hidden_state_input\n",
        "decoder_combined_context_inf = Concatenate(axis=-1)([context_inf, decoder_lstm_outputs_inf])\n",
        "\n",
        "# DENSE LAYER (giống hệt training!)\n",
        "decoder_dense = Dense(VOCAB_SIZE, activation='softmax')\n",
        "decoder_outputs_inf = decoder_dense(decoder_combined_context_inf)\n",
        "\n",
        "# Tạo decoder model mới với architecture đúng\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs_single, decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs_inf, state_h_inf, state_c_inf]\n",
        ")\n",
        "\n",
        "print(\"Decoder model rebuilt với attention mechanism!\")\n",
        "decoder_model.summary()"
      ],
      "metadata": {
        "id": "zKDjbDvX-2mt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "92ee3712-5fc1-417e-b284-fb1545c2978c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder model rebuilt với attention mechanism!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_26      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_11        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │     \u001b[38;5;34m32,000\u001b[0m │ input_layer_26[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_27      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_28      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m394,240\u001b[0m │ embedding_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ input_layer_27[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ input_layer_28[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_29      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ additive_attention… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ lstm_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ input_layer_29[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ input_layer_29[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ additive_attenti… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lstm_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m250\u001b[0m)    │    \u001b[38;5;34m128,250\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_26      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_11        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,000</span> │ input_layer_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_27      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_28      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ input_layer_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ input_layer_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_29      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ additive_attention… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ input_layer_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ input_layer_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ additive_attenti… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lstm_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">128,250</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m554,746\u001b[0m (2.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">554,746</span> (2.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m554,746\u001b[0m (2.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">554,746</span> (2.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_decode(input_seq, beam_width=2, max_len=MAX_DECODER_LEN):\n",
        "    # Bước 1: Encode input\n",
        "    enc_outs, state_h, state_c = encoder_model.predict(input_seq, verbose=0)\n",
        "\n",
        "    # Bước 2: Khởi tạo beam (sequence, score, hidden states)\n",
        "    beams = [([shared_tokenizer.word_index['<start>']], 1.0, state_h, state_c)]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        candidates = []\n",
        "        for seq, score, h, c in beams:\n",
        "            # Dừng nếu gặp <end>\n",
        "            if seq[-1] == shared_tokenizer.word_index['<end>']:\n",
        "                candidates.append((seq, score, h, c))\n",
        "                continue\n",
        "\n",
        "            # Bước 3: Dự đoán từ tiếp theo\n",
        "            target_seq = np.array([[seq[-1]]])\n",
        "            output_tokens, h_new, c_new = decoder_model.predict(\n",
        "                [target_seq, enc_outs, h, c], verbose=0)\n",
        "\n",
        "            # Lấy top-k từ (beam_width)\n",
        "            probs = output_tokens[0, -1, :]\n",
        "            top_k = np.argsort(probs)[-beam_width:]  # Lấy indices của top-k\n",
        "\n",
        "            for token in top_k:\n",
        "                new_seq = seq + [token]\n",
        "                new_score = score * probs[token]\n",
        "                candidates.append((new_seq, new_score, h_new, c_new))\n",
        "\n",
        "        # Bước 4: Chọn beam_width ứng viên tốt nhất\n",
        "        beams = sorted(candidates, key=lambda x: x[1])[-beam_width:]\n",
        "\n",
        "    # Bước 5: Trả về câu có điểm cao nhất (loại bỏ <start> và <end>)\n",
        "    best_seq = beams[-1][0][1:]  # Bỏ <start>\n",
        "    decoded_sentence = []\n",
        "    for idx in best_seq:\n",
        "        if idx == shared_tokenizer.word_index['<end>']:\n",
        "            break\n",
        "        decoded_sentence.append(shared_tokenizer.index_word.get(idx, '<OOV>'))\n",
        "\n",
        "    return ' '.join(decoded_sentence)"
      ],
      "metadata": {
        "id": "vujXDklVh40M"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = input(\"Bạn: \")\n",
        "user_input_seq = shared_tokenizer.texts_to_sequences([clean_text(user_input)])\n",
        "user_input_padded = pad_sequences(user_input_seq, maxlen=MAX_ENCODER_LEN, padding='post')\n",
        "\n",
        "# Dùng Beam Search thay vì decode_sequence cũ\n",
        "print(\"Bot (Beam Search):\", beam_decode(user_input_padded, beam_width=3))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOaVWhodh8Z4",
        "outputId": "3aa87fd9-a42d-4054-880b-da09275ba99a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bạn: xin chào\n",
            "Bot (Beam Search): thức thức thức thức thức thức thức thức thức thức thức thức thức thức dữ dữ dữ dữ dữ dữ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test nhanh chất lượng model hiện tại\n",
        "test_samples = [\n",
        "    (\"xin chào\", \"chào bạn\"),\n",
        "    (\"cảm ơn\", \"không có gì\")\n",
        "]\n",
        "\n",
        "for input_text, true_output in test_samples:\n",
        "    input_seq = shared_tokenizer.texts_to_sequences([input_text])\n",
        "    padded = pad_sequences(input_seq, maxlen=MAX_ENCODER_LEN, padding='post')\n",
        "    pred = beam_decode(padded)\n",
        "    print(f\"Input: {input_text} | Pred: {pred} | True: {true_output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "TIP92801imzQ",
        "outputId": "ecf8c69b-2dfa-4611-ce06-a0f8a21415b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'shared_tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-4163144711.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_ENCODER_LEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'shared_tokenizer' is not defined"
          ]
        }
      ]
    }
  ]
}